{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Setting up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyork = \"https://www.airbnb.com/s/New-York--NY--United-States/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&query=New%20York%2C%20NY%2C%20United%20States&place_id=ChIJOwg_06VPwokRYv534QaPC8g&source=structured_search_input_header&search_type=autocomplete_click\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/yingli/Documents/git_project/airbnb_scraping/chromedriver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url):\n",
    "    ''' returns a soup object that contains all the information \n",
    "    of a certain webpage'''\n",
    "    result = requests.get(url)\n",
    "    content = result.content\n",
    "    return bs(content, features = \"lxml\")\n",
    "\n",
    "    \n",
    "def getRoomClasses(soupPage):\n",
    "    ''' This function returns all the listings that can \n",
    "    be found on the page in a list.'''\n",
    "    rooms = soupPage.findAll(\"div\", {\"class\": \"_8ssblpx\"})\n",
    "    result = []\n",
    "    for room in rooms:\n",
    "        result.append(room)\n",
    "    return result\n",
    "\n",
    "def getListingLink(listing):\n",
    "    ''' This function returns the link of the listing'''\n",
    "    return \"http://airbnb.com\" + listing.find(\"a\")[\"href\"]\n",
    "\n",
    "def getListingTitle(listing):\n",
    "    ''' This function returns the title of the listing'''\n",
    "    return listing.find(\"meta\")[\"content\"]\n",
    "\n",
    "def getTopRow(listing):\n",
    "    ''' Returns the top row of listing information'''\n",
    "    return listing.find(\"div\", {\"class\": \"_167qordg\"}).text\n",
    "\n",
    "def getRoomInfo(listing):\n",
    "    ''' Returns the guest information'''\n",
    "    return listing.find(\"div\", {\"class\":\"_kqh46o\"}).text\n",
    "\n",
    "def getBasicFacilities(listing):\n",
    "    ''' Returns the basic facilities'''\n",
    "    try:\n",
    "        output = listing.findAll(\"div\", {\"class\":\"_kqh46o\"})[1].text.replace(\" \",\"\") #Speeds up cleaning\n",
    "    except:\n",
    "        output = []\n",
    "    return output\n",
    "\n",
    "def getListingPrice(listing):\n",
    "    ''' Returns the price'''\n",
    "    return listing.find(\"div\", {\"class\":\"_1fwiw8gv\"}).text\n",
    "\n",
    "def getListingRating(listing):\n",
    "    ''' Returns the rating '''\n",
    "    try: # Not all listings have ratings\n",
    "        output = listing.find(\"span\", {\"class\":\"_krjbj\"}).text\n",
    "    except:\n",
    "        output = -1\n",
    "    return output\n",
    "\n",
    "def getListingReviewNumber(listing):\n",
    "    ''' Returns the number of reviews '''\n",
    "    try: # Not all listings have reviews // extraction failed\n",
    "        output = listing.findAll(\"span\", {\"class\":\"_krjbj\"})[1].text\n",
    "    except:\n",
    "        output = -1   # Indicate that the extraction failed -> can indicate no reviews or a mistake in scraping\n",
    "    return output\n",
    "\n",
    "def extractInformation(soupPage):\n",
    "    ''' Takes all the information of a single page (thus multiple listings) and\n",
    "    summarizes it in a dataframe'''\n",
    "    listings = getRoomClasses(soupPage)\n",
    "    titles, links, toprows, roominfos, basicfacilitiess, prices, ratings, reviews = [], [], [], [], [], [], [], []\n",
    "    for listing in listings:\n",
    "        titles.append(getListingTitle(listing))\n",
    "        links.append(getListingLink(listing))\n",
    "        toprows.append(getTopRow(listing))\n",
    "        roominfos.append(getRoomInfo(listing))\n",
    "        basicfacilitiess.append(getBasicFacilities(listing))\n",
    "        prices.append(getListingPrice(listing))\n",
    "        ratings.append(getListingRating(listing))\n",
    "        reviews.append(getListingReviewNumber(listing))\n",
    "    dictionary = {\"title\": titles, \"toprow\": toprows, \"roominfo\": roominfos, \"facilities\" : basicfacilitiess, \"price\": prices, \"rating\": ratings, \"link\": links, \"reviewnumber\": reviews}\n",
    "    return pd.DataFrame(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scraping all listings for a given city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNextPage(soupPage):\n",
    "    ''' Finds the next page with listings if it exists '''\n",
    "    try:\n",
    "        nextpage = \"https://airbnb.com\" + soupPage.find(\"li\", {\"class\": \"_i66xk8d\"}).find(\"a\")[\"href\"]\n",
    "    except:\n",
    "        nextpage = \"no next page\"\n",
    "    return nextpage\n",
    "\n",
    "def getPages(url):\n",
    "    ''' This function returns all the links to the pages containing \n",
    "    listings for one particular city '''\n",
    "    result = []\n",
    "    while url != \"no next page\": \n",
    "        page = getPage(url)\n",
    "        result = result + [page]\n",
    "        url = findNextPage(page)\n",
    "    return result\n",
    "\n",
    "def extractPages(url):\n",
    "    ''' This function outputs a dataframe that contains all information of a particular\n",
    "    city. It thus contains information of multiple listings coming from multiple pages.'''\n",
    "    pages = getPages(url)\n",
    "    # Do for the first element to initialize the dataframe\n",
    "    df = extractInformation(pages[0])\n",
    "    # Loop over all other elements of the dataframe\n",
    "    for pagenumber in range(1, len(pages)):\n",
    "        df = df.append(extractInformation(pages[pagenumber]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all listings for a collection of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [[\"New York\", newyork],\n",
    "         [\"Tokyo\", tokyo],\n",
    "         [\"Beijing\", beijing],\n",
    "         [\"Seoul\", seoul],\n",
    "         [\"Bangkok\", bangkok],\n",
    "         [\"Sydney\", sydney],\n",
    "         [\"Auckland\", auckland],\n",
    "         [\"Kinshasa\", kinshasa],\n",
    "         [\"Cape Town\", cape_town],\n",
    "         [\"Cairo\", cairo],\n",
    "         [\"New Delhi\", new_delhi],\n",
    "         [\"Amman\", amman],\n",
    "         [\"Brussels\", brussels],\n",
    "         [\"Krakau\", krakau],\n",
    "         [\"Rome\", rome],\n",
    "         [\"Montreal\", montreal],\n",
    "         [\"San Francisco\", sanfrancisco],\n",
    "         [\"Charlotte\", charlotte],\n",
    "         [\"Mexico City\", mexicostad],\n",
    "         [\"San Jose (Costa Rica)\", sanjose],\n",
    "         [\"Rio de Janeiro\", rio],\n",
    "         [\"Santiago\", santiago],\n",
    "         [\"London\", london]\n",
    "         ]\n",
    "\n",
    "\n",
    "def scrapeURLs(listofURLs):\n",
    "    ''' This function scrapes all listings of the cities listed in a list together\n",
    "    with their URLs'''\n",
    "    print(\"city \" + listofURLs[0][0] + \" is being scraped\") # Shows which city is being scraped\n",
    "    # Do it for the first element in the list to initialize dataframe\n",
    "    df = extractPages(listofURLs[0][1])\n",
    "    df.loc[:, \"city\"] = listofURLs[0][0] # Add the city as a feature\n",
    "    # loop over all the other elements in the list and append to dataframe\n",
    "    for i in range(1, len(listofURLs)):\n",
    "        print(\"city \" + listofURLs[i][0] + \" is being scraped\") # Shows which city is being scraped\n",
    "        newrows = extractPages(listofURLs[i][1])\n",
    "        newrows.loc[:, \"city\"] = listofURLs[i][0] # Add the city as a feature\n",
    "        df = df.append(newrows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping detailed information of rooms with beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescription(detailpage):\n",
    "    ''' Returns the self written description of the host '''\n",
    "    return detailpage.find(\"div\", {\"class\": \"_eeq7h0\"}).text\n",
    "\n",
    "def getDetailedScores(detailpage):\n",
    "    output = []\n",
    "    scores = detailpage.findAll(class_ = '_a3qxec')\n",
    "    try: # sometimes a listing does not have any reviews\n",
    "        for i in range(0, 6):\n",
    "            split = scores[i].text.split(\".\")\n",
    "            output.append(float(split[0][-1] + \".\" + split[1]))\n",
    "    except: # then we just don't want to pass any scores\n",
    "        pass\n",
    "    return output\n",
    "\n",
    "def getHostInfo(detailpage):\n",
    "    ''' Returns the name of the host and when they joined'''\n",
    "#    return detailpage.find(class_ = \"_f47qa6\").text\n",
    "    return detailpage.find(class_ = \"_svr7sj\").text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using selenium for all other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupDriver(url, waiting_time = 2.5):\n",
    "    ''' Initializes the driver of selenium'''\n",
    "    driver = webdriver.Chrome(executable_path=path)\n",
    "    driver.get(url)\n",
    "    time.sleep(waiting_time) \n",
    "    return driver\n",
    "\n",
    "\n",
    "def getJSpage(url):\n",
    "    ''' Extracts the html of the webpage including the JS elements,\n",
    "    output should be used as the input for all functions extracting specific information\n",
    "    from the detailed pages of the listings '''\n",
    "    driver = setupDriver(url)\n",
    "    try:\n",
    "#        read_more_buttons = driver.find_elements_by_class_name(\"_1d079j1e\")\n",
    "        read_more_buttons = driver.find_elements_by_class_name(\"_ejra3kg\")\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    try:\n",
    "        for i in range(2, len(read_more_buttons)):\n",
    "            read_more_buttons[i].click()\n",
    "    except:\n",
    "        pass\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    return bs(html, features=\"lxml\") \n",
    "\n",
    "\n",
    "def getAmenitiesPage(detailpage):\n",
    "    ''' This code fetches the html of the webpage containing the information\n",
    "     about the amenities that are available in the room'''\n",
    "    \n",
    "#    link = detailpage.find(class_ = \"_1v4ygly5\")[\"href\"]\n",
    "    link = detailpage.find(class_ = \"_13e0raay\")[\"href\"]\n",
    "    driver = setupDriver(\"https://airbnb.com\" + link, 5) # Amenitiespage is a link disguished as a button, this is why I need to do this\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    return bs(html, features=\"lxml\")\n",
    "\n",
    "            \n",
    "first = True # These variables were coded in a smarter way when doing the actual analysis\n",
    "scraped = 0  # It used the length of the intermediate_results_par dataset stored on the pc\n",
    "def getAddis(url): \n",
    "    ''' This function is used to extract the html of the additional pages (detail page and amenities page)'''\n",
    "    global first\n",
    "    global scraped  \n",
    "    output = pd.DataFrame(columns=[\"details_page\", \"amenities_page\", \"link\"])\n",
    "    try:\n",
    "        dp = getJSpage(url)    # dp is the soup result from read more (detailpage)\n",
    "        ap = getAmenitiesPage(dp)\n",
    "        output.loc[0] = [dp, ap, url]\n",
    "    except:\n",
    "        dp = getJSpage(url)\n",
    "        output.loc[0] = [-1, -1, url]\n",
    "    if first: # Ensures that the columns have the correct titles because apparently that's difficult\n",
    "        output.to_csv('intermediate_results_par.csv', mode='a', header=True, index = False)\n",
    "        first = False\n",
    "    else:\n",
    "        output.to_csv('intermediate_results_par.csv', mode='a', header=False, index = False) \n",
    "    scraped += 1\n",
    "    print(\"Scraped: {}\".format(scraped))\n",
    "    \n",
    "# Extract Javascript enabled information    \n",
    "def getReviews(detailpage):\n",
    "    ''' Returns a list of the featured reviews on the page '''\n",
    " #   reviews = detailpage.findAll(class_ = \"_50mnu4\")\n",
    "    reviews = detailpage.findAll(class_ = \"_1y6fhhr\")\n",
    "    output = \"\"\n",
    "    for review in reviews:\n",
    "        output += review.text + \"**-**\" #**-** can be used to split reviews later again\n",
    "    return output\n",
    "\n",
    "\n",
    "def getAmenities(amenitiespage):\n",
    "    amenities = amenitiespage.findAll(class_ = \"_vzrbjl\")\n",
    "    output = \"\"\n",
    "    for amenity in amenities:\n",
    "        output += re.findall('[A-Z][^A-Z]*', amenity.text)[0] + \"**-**\" # **-** will be used to split the string later for the purpose of dummification\n",
    "    return output\n",
    "\n",
    "def getResponseInfo(detailpage):\n",
    "    try:\n",
    "        output = detailpage.find(class_ = \"_jofnfy\").text\n",
    "    except:\n",
    "        output = \"\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean functions basic data frame extracted using only beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFacilities(df): # Treating the facilities as a bag of words to create dummy variables\n",
    "    df.loc[:, \"facilities\"] = df[\"facilities\"].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "    vectorizer = CountVectorizer(decode_error = \"ignore\") \n",
    "    X = vectorizer.fit_transform(df.facilities)\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    return pd.concat([df.reset_index(drop=True).drop(\"facilities\", axis = 1), bag_of_words], axis=1)\n",
    "\n",
    "def cleanTitle(df):\n",
    "    df.loc[:, \"name\"] = df[\"title\"].str.split(\" null \", n = 0, expand = True)[0].str.replace(\"-\", \"\")\n",
    "    df.loc[:, \"location\"] = df[\"title\"].str.split(\" null \", n = 0, expand = True)[1].str.replace(\"-\", \"\").str.strip()\n",
    "    return df.drop(\"title\", axis = 1)\n",
    "\n",
    "def cleanTopRow(df):\n",
    "    df.loc[:, 'roomtype'] = df[\"toprow\"].str.split(\" in \", n = 0, expand = True)[0] \n",
    "    df.loc[:, 'detailed_location'] = df[\"toprow\"].str.split(\" in \", n = 0, expand = True)[1] \n",
    "    return df.drop(\"toprow\", axis = 1)\n",
    "\n",
    "def cleanRoomInfo(df):\n",
    "    df.loc[:, \"guests\"] = df.loc[:, \"roominfo\"].str.split(\" · \", n = 0, expand = True)[0].str.replace(\" guests\", \"\")\n",
    "    df.loc[:, \"bedrooms\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n = 0, expand = True)[1]\n",
    "    df.loc[:, \"beds\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n = 0, expand = True)[2].str.replace(\" bed\", \"\").str.replace(\"s\", \"\")\n",
    "    df.loc[:, \"bathrooms\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n = 0, expand = True)[3]\n",
    "    df.loc[:, \"guests\"] = pd.to_numeric(df.guests, errors = 'coerce')\n",
    "    df.loc[:, \"beds\"] = pd.to_numeric(df.beds, errors = 'coerce')\n",
    "    df.loc[:, \"bedrooms\"] = pd.to_numeric(df.bedrooms.str.split(\" \", n = 0, expand = True)[0], errors = \"ignore\")\n",
    "    df.loc[:, \"bathrooms\"] = pd.to_numeric(df.bathrooms.str.split(\" \", n = 0, expand = True)[0], errors = \"ignore\")\n",
    "    return df.drop(\"roominfo\", axis = 1)\n",
    "\n",
    "def cleanPrice(df):\n",
    "    try: # not all rooms have discounted price\n",
    "        df.loc[:, \"pricepernight\"] = df.loc[:, \"price\"].str.split(\"Discounted\", n = 0, expand = True)[0].str.replace(\"$\", \"/\").str.split(\"/\",  n = 0, expand = True)[1]\n",
    "        df.loc[:, 'discountedpricepernight'] = df.loc[:, \"price\"].str.split(\"Discounted\", n = 0, expand = True)[1].str.replace(\"$\", \"/\").str.split(\"/\",  n = 0, expand = True)[1]\n",
    "        df.loc[:, \"price\"] = pd.to_numeric(df.pricepernight.str.replace(\",\",\"\").str.strip())\n",
    "        df.loc[:, \"discountedprice\"] = pd.to_numeric(df.discountedpricepernight.str.replace(\" \", \"\").str.replace(\",\",\"\"), errors = \"coerce\")\n",
    "        return df.drop([\"pricepernight\", \"discountedpricepernight\"], axis = 1)\n",
    "    except:\n",
    "        df.loc[:, \"pricepernight\"] = df.loc[:, \"price\"].str.split(\"Discounted\", n = 0, expand = True)[0].str.replace(\"$\", \"/\").str.split(\"/\",  n = 0, expand = True)[1]\n",
    "        df.loc[:, \"price\"] = pd.to_numeric(df.pricepernight.str.replace(\",\",\"\").str.strip())\n",
    "        return df.drop([\"pricepernight\"], axis = 1)\n",
    "\n",
    "def cleanRating(df):\n",
    "    df.loc[:, \"score\"] = df.loc[:, 'rating'].str.split(\" \", n = 0, expand = True)[1]\n",
    "    df.loc[:, \"score\"] = pd.to_numeric(df.score, errors = \"coerce\")\n",
    "    return df.drop(\"rating\", axis = 1)\n",
    "\n",
    "def cleanReviewNumber(df):\n",
    "    df.loc[:, \"reviewnumber\"] = df.loc[:, 'reviewnumber'].str.split(\" \", n = 0, expand = True)[0]\n",
    "    df.loc[:, \"reviewnumber\"] = pd.to_numeric(df.reviewnumber, errors = \"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean(df):\n",
    "    df = cleanTitle(df)\n",
    "    df = cleanFacilities(df)\n",
    "    df = cleanTopRow(df)\n",
    "    df = cleanRoomInfo(df)\n",
    "    df = cleanPrice(df)\n",
    "    df = cleanRating(df)\n",
    "    df = cleanReviewNumber(df)\n",
    "    # Reorder columns\n",
    "    col1 = df.pop('price')\n",
    "    df = pd.concat([df.reset_index(drop=True), col1], axis=1)\n",
    "    col2 = df.pop('reviewnumber')\n",
    "    df = pd.concat([df.reset_index(drop=True), col2], axis=1) \n",
    "    col3 = df.pop('link')\n",
    "    df = pd.concat([df.reset_index(drop=True), col3], axis=1) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clean functions data frame containing the html of the additional pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAmenities(df):\n",
    "    df.loc[:, \"amenities\"] = df.amenities.replace(np.nan, '', regex=True)# fit_transform cannot handle missing values\n",
    "    df.loc[:, \"amenities\"] = df.amenities.str.replace(\" \", \"_\").str.replace(\"-\", \" \").str.replace(\"*\", \"\") #split in two because of a python bug (https://stackoverflow.com/questions/3675144/regex-error-nothing-to-repeat)\n",
    "    vectorizer = CountVectorizer(decode_error = \"ignore\") \n",
    "    X = vectorizer.fit_transform(df.amenities)\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    return pd.concat([df.reset_index(drop=True).drop(\"amenities\", axis = 1), bag_of_words], axis=1)\n",
    "\n",
    "def cleanReviews(df):\n",
    "    df.loc[:, \"reviews\"] = df.reviews.replace(np.nan, '', regex=True)# fit_transform cannot handle missing values\n",
    "    df.loc[:, \"reviews\"] = df.reviews.str.split(\"-\")\n",
    "    return df\n",
    "\n",
    "def getResponseTime(string):\n",
    "    if \"Response time\" in string:\n",
    "        output = string[string.find(\"Response time\") + 15:]\n",
    "    else:\n",
    "        output = \"Unknown\"\n",
    "    return output\n",
    "\n",
    "def getResponseRate(string):\n",
    "    if \"Response rate\" in string:\n",
    "        temp = string[string.find(\"Response rate\") + 15:string.find(\"Response rate\")+20] \n",
    "        output = \"\"\n",
    "        for letter in temp:\n",
    "            if letter in \"0123456789\":\n",
    "                output += letter\n",
    "    else:\n",
    "        output = \"Unknown\"      \n",
    "    return output\n",
    "\n",
    "def getLanguages(string):\n",
    "    if \"Language\" in string:\n",
    "        if \"Response\" in string:\n",
    "            output = string[10:string.find(\"Response\")].strip()\n",
    "        else:\n",
    "            output = string[10:].strip()\n",
    "    else:\n",
    "        output = \"Unknown\"\n",
    "    return output\n",
    "\n",
    "def cleanResponseTime(df):\n",
    "    df.loc[:, \"response_info\"] = df.response_info.replace(np.nan, '', regex=True)\n",
    "    df.loc[:, \"response_time\"] = df.response_info.apply(lambda x: getResponseTime(x))\n",
    "    return df\n",
    "\n",
    "def cleanResponseRate(df):\n",
    "    df.loc[:, \"response_rate\"] = df.response_info.apply(lambda x: getResponseRate(x))\n",
    "    return df\n",
    "\n",
    "def cleanLanguages(df):\n",
    "    df.loc[:, \"languages\"] = df.response_info.apply(lambda x: getLanguages(x))\n",
    "    df.loc[:, \"languages\"] = df.languages.str.split(\",\")\n",
    "    return df\n",
    "\n",
    "def cleanResponseInfo(df):\n",
    "    df = cleanResponseTime(df)\n",
    "    df = cleanResponseRate(df)\n",
    "    df = cleanLanguages(df)\n",
    "    return df.drop(\"response_info\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(urls, sample_size = None, random_state = 1234):\n",
    "    df = scrapeURLs(urls)\n",
    "    df = clean(df)\n",
    "    if sample_size is not None:\n",
    "        df = df.sample(sample_size, random_state = random_state)\n",
    "    Parallel(n_jobs = -1, prefer=\"threads\")(delayed(getAddis)(url) for url in df.link)\n",
    "    df2 = pd.read_csv(\"intermediate_results_par.csv\")\n",
    "    df = df.merge(df2, on = \"link\")\n",
    "    df.loc[:, 'reviews'] = df.details_page.apply(lambda x: getReviews(bs(x, features = \"lxml\")))\n",
    "    df.loc[:, 'response_info'] = df.details_page.apply(lambda x: getResponseInfo(bs(x, features = \"lxml\")))\n",
    "    df.loc[:, \"amenities\"] = df.amenities_page.apply(lambda x: getAmenities(bs(x, features = \"lxml\")))\n",
    "    df = cleanReviews(df)\n",
    "    df = cleanResponseInfo(df)\n",
    "    df = cleanAmenities(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running te scraper on New York and Tokyo and outputting a sample of 10 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city New York is being scraped\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 3\n",
      "Scraped: 4\n",
      "X work out 3\n",
      "Scraped: 5\n",
      "X work out 3\n",
      "Scraped: 6\n",
      "X work out 3\n",
      "Scraped: 7\n",
      "X work out 3\n",
      "Scraped: 8\n",
      "X work out 3\n",
      "Scraped: 9\n",
      "X work out 3\n",
      "Scraped: 10\n",
      "X work out 2\n",
      "Scraped: 11\n",
      "X work out 1\n",
      "X work out 1\n",
      "X work out 2\n",
      "Scraped: 12\n",
      "X work out 2\n",
      "Scraped: 13\n",
      "here 5\n",
      "here 6\n"
     ]
    }
   ],
   "source": [
    "#urls2 = [[\"New York\", newyork],\n",
    "#         [\"Tokyo\", tokyo]]\n",
    "urls2 = [[\"New York\", newyork]\n",
    "         ]\n",
    "df = scraper(urls2, sample_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>dishwasher</th>\n",
       "      <th>dryer</th>\n",
       "      <th>elevator</th>\n",
       "      <th>freeparking</th>\n",
       "      <th>gym</th>\n",
       "      <th>...</th>\n",
       "      <th>luggage_dropoff_allowed</th>\n",
       "      <th>microwave</th>\n",
       "      <th>oven</th>\n",
       "      <th>paid_parking_off_premises</th>\n",
       "      <th>refrigerator</th>\n",
       "      <th>shampoo</th>\n",
       "      <th>smoke_alarm</th>\n",
       "      <th>stove</th>\n",
       "      <th>unavailable</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>Brilliant BR w/ Private Bath near LGA &amp; Manhat...</td>\n",
       "      <td>Queens</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>Renovated Designed Studio, SwimmingPool Access .</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>Great private studio with beautiful backyard</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>Luxury ADA King Room</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>Lively Rm w/Private Entrance &amp; Bath</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York</td>\n",
       "      <td>Modern Brooklyn Studio One Block From BTrain</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York</td>\n",
       "      <td>Cosy 2bedroom apartment near Manhattan</td>\n",
       "      <td>Union City</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New York</td>\n",
       "      <td>PRIME Location! Midtown Private Room 2Queen Bed</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New York</td>\n",
       "      <td>Cozy Studio in Gramercy park</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New York</td>\n",
       "      <td>Located Between Times Square and Theater Distr...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       city                                               name    location  \\\n",
       "0  New York  Brilliant BR w/ Private Bath near LGA & Manhat...      Queens   \n",
       "1  New York  Renovated Designed Studio, SwimmingPool Access .     Brooklyn   \n",
       "2  New York      Great private studio with beautiful backyard     Brooklyn   \n",
       "3  New York                              Luxury ADA King Room     NEW YORK   \n",
       "4  New York               Lively Rm w/Private Entrance & Bath     Brooklyn   \n",
       "5  New York      Modern Brooklyn Studio One Block From BTrain     Brooklyn   \n",
       "6  New York            Cosy 2bedroom apartment near Manhattan   Union City   \n",
       "7  New York   PRIME Location! Midtown Private Room 2Queen Bed     New York   \n",
       "8  New York                      Cozy Studio in Gramercy park     New York   \n",
       "9  New York  Located Between Times Square and Theater Distr...    New York   \n",
       "\n",
       "   airconditioning  breakfast  dishwasher  dryer  elevator  freeparking  gym  \\\n",
       "0                0          0           0      0         0            0    0   \n",
       "1                0          0           0      0         0            0    0   \n",
       "2                1          0           0      0         0            0    0   \n",
       "3                0          0           0      0         0            0    0   \n",
       "4                0          0           0      0         0            0    0   \n",
       "5                0          0           0      0         0            0    0   \n",
       "6                0          0           0      0         0            0    0   \n",
       "7                1          0           0      0         0            0    0   \n",
       "8                1          0           0      0         0            0    0   \n",
       "9                0          0           0      0         1            0    1   \n",
       "\n",
       "   ...  luggage_dropoff_allowed  microwave  oven  paid_parking_off_premises  \\\n",
       "0  ...                        1          1     1                          0   \n",
       "1  ...                        0          0     0                          0   \n",
       "2  ...                        0          0     0                          0   \n",
       "3  ...                        0          0     0                          0   \n",
       "4  ...                        0          0     0                          0   \n",
       "5  ...                        0          0     0                          0   \n",
       "6  ...                        0          0     0                          0   \n",
       "7  ...                        0          0     0                          0   \n",
       "8  ...                        0          0     0                          0   \n",
       "9  ...                        1          0     0                          1   \n",
       "\n",
       "   refrigerator  shampoo  smoke_alarm  stove  unavailable  wifi  \n",
       "0             1        0            1      1            6     1  \n",
       "1             0        0            0      0            0     0  \n",
       "2             0        0            0      0            0     0  \n",
       "3             0        0            0      0            0     0  \n",
       "4             0        0            0      0            0     0  \n",
       "5             0        0            0      0            0     0  \n",
       "6             0        0            0      0            0     0  \n",
       "7             0        0            0      0            0     0  \n",
       "8             0        0            1      0            4     1  \n",
       "9             0        1            1      0            2     1  \n",
       "\n",
       "[10 rows x 72 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 72 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   city                        10 non-null     object \n",
      " 1   name                        10 non-null     object \n",
      " 2   location                    10 non-null     object \n",
      " 3   airconditioning             10 non-null     int64  \n",
      " 4   breakfast                   10 non-null     int64  \n",
      " 5   dishwasher                  10 non-null     int64  \n",
      " 6   dryer                       10 non-null     int64  \n",
      " 7   elevator                    10 non-null     int64  \n",
      " 8   freeparking                 10 non-null     int64  \n",
      " 9   gym                         10 non-null     int64  \n",
      " 10  heating                     10 non-null     int64  \n",
      " 11  hottub                      10 non-null     int64  \n",
      " 12  in                          10 non-null     int64  \n",
      " 13  indoorfireplace             10 non-null     int64  \n",
      " 14  kitchen                     10 non-null     int64  \n",
      " 15  petsallowed                 10 non-null     int64  \n",
      " 16  pool                        10 non-null     int64  \n",
      " 17  selfcheck                   10 non-null     int64  \n",
      " 18  washer                      10 non-null     int64  \n",
      " 19  waterfront                  10 non-null     int64  \n",
      " 20  wifi                        10 non-null     int64  \n",
      " 21  roomtype                    10 non-null     object \n",
      " 22  detailed_location           10 non-null     object \n",
      " 23  guests                      10 non-null     float64\n",
      " 24  bedrooms                    10 non-null     object \n",
      " 25  beds                        10 non-null     float64\n",
      " 26  bathrooms                   10 non-null     float64\n",
      " 27  score                       9 non-null      float64\n",
      " 28  price                       10 non-null     int64  \n",
      " 29  reviewnumber                9 non-null      float64\n",
      " 30  link                        10 non-null     object \n",
      " 31  details_page                10 non-null     object \n",
      " 32  amenities_page              10 non-null     object \n",
      " 33  reviews                     10 non-null     object \n",
      " 34  response_time               10 non-null     object \n",
      " 35  response_rate               10 non-null     object \n",
      " 36  languages                   10 non-null     object \n",
      " 37  air_conditioning            10 non-null     int64  \n",
      " 38  bed_linens                  10 non-null     int64  \n",
      " 39  building_staff              10 non-null     int64  \n",
      " 40  cable_                      10 non-null     int64  \n",
      " 41  carbon_monoxide_alarm       10 non-null     int64  \n",
      " 42  cleaning_before_checkout    10 non-null     int64  \n",
      " 43  cooking_basics              10 non-null     int64  \n",
      " 44  dishes_and_silverware       10 non-null     int64  \n",
      " 45  elevator                    10 non-null     int64  \n",
      " 46  essentials                  10 non-null     int64  \n",
      " 47  extra_pillows_and_blankets  10 non-null     int64  \n",
      " 48  fire_extinguisher           10 non-null     int64  \n",
      " 49  first_aid_kit               10 non-null     int64  \n",
      " 50  free_street_parking         10 non-null     int64  \n",
      " 51  friendly_workspace          10 non-null     int64  \n",
      " 52  gym                         10 non-null     int64  \n",
      " 53  hair_dryer                  10 non-null     int64  \n",
      " 54  hangers                     10 non-null     int64  \n",
      " 55  heating                     10 non-null     int64  \n",
      " 56  hot_water                   10 non-null     int64  \n",
      " 57  iron                        10 non-null     int64  \n",
      " 58  kitchen                     10 non-null     int64  \n",
      " 59  laptop                      10 non-null     int64  \n",
      " 60  lockbox                     10 non-null     int64  \n",
      " 61  long_term_stays_allowed     10 non-null     int64  \n",
      " 62  luggage_dropoff_allowed     10 non-null     int64  \n",
      " 63  microwave                   10 non-null     int64  \n",
      " 64  oven                        10 non-null     int64  \n",
      " 65  paid_parking_off_premises   10 non-null     int64  \n",
      " 66  refrigerator                10 non-null     int64  \n",
      " 67  shampoo                     10 non-null     int64  \n",
      " 68  smoke_alarm                 10 non-null     int64  \n",
      " 69  stove                       10 non-null     int64  \n",
      " 70  unavailable                 10 non-null     int64  \n",
      " 71  wifi                        10 non-null     int64  \n",
      "dtypes: float64(5), int64(54), object(13)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
